## kafka
### 怎么查看kafka的offset
0.9版本以上，可以用最新的Consumer client 客户端，有
```
consumer.seekToEnd()
consumer.position()
``` 
可以用于得到当前最新的offset

---
###kafka的数据存在内存还是磁盘
Kafka最核心的思想是使用磁盘，而不是使用内存，可能所有人都会认为，内存的速度一定比磁盘快，我也不例外。在看了Kafka的设计思想，查阅了相应资料再加上自己的测试后，发现磁盘的顺序读写速度和内存持平。
而且Linux对于磁盘的读写优化也比较多，包括read-ahead和write-behind，磁盘缓存等。如果在内存做这些操作的时候，一个是JAVA对象的内存开销很大，另一个是随着堆内存数据的增多，JAVA的GC时间会变得很长。
使用磁盘操作有以下几个好处：
    - 磁盘缓存由Linux系统维护，减少了程序员的不少工作。
    - 磁盘顺序读写速度超过内存随机读写。
    - JVM的GC效率低，内存占用大。使用磁盘可以避免这一问题。
    - 系统冷启动后，磁盘缓存依然可用。
    
###怎么解决kafka的数据丢失
- producer端：
宏观上看保证数据的可靠安全性，肯定是依据分区数做好数据备份，设立副本数。
- broker端：
topic设置多分区，分区自适应所在机器，为了让各分区均匀分布在所在的broker中，分区数要大于broker数。
分区是kafka进行并行读写的单位，是提升kafka速度的关键。
- Consumer端
consumer端丢失消息的情形比较简单：如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失。由于Kafka consumer默认是自动提交位移的，所以在后台提交位移前一定要保证消息被正常处理了，因此不建议采用很重的处理逻辑，如果处理耗时很长，则建议把逻辑放到另一个线程中去做。为了避免数据丢失，现给出两点建议：
enable.auto.commit=false 关闭自动提交位移
在消息被完整处理之后再手动提交位移

---
### kafka集群的规模，消费速度是多少。

一般中小型公司是10个节点，每秒20M左右。

---
### 了解zookeeper吗？介绍一下它，它的选举机制和集群的搭建。
答：那当然是熟悉啦，ZooKeeper 是一个开源的分布式协调服务，是 Google Chubby 的开源实现。分布式应用程序可以基于 ZooKeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。我们公司使用的flume集群，Kafka集群等等，都离不开ZooKeeper呀。每个节点上我们都要搭建ZooKeeper服务。首先我们要在每台pc上配置zookeeper环境变量，在cd到zookeeper下的conf文件夹下在zoo_simjle.cfg文件中添加datadir路径，再到zookeeper下新建data文件夹，创建myid，在文件里添加上server的ip地址。在启动zkserver.sh start便ok了。
## flume
### Flume的工作机制是什么

核心概念是agent，里面包括source，channel和sink三个组件。

Source运行在日志收集节点进行日志采集，之后临时存储在channel中，sink负责将channel中的数据发送到目的地。

只有发送成功channel中的数据才会被删除。

首先书写flume配置文件，定义agent、source、channel和sink然后将其组装，执行flume-ng命令。

---
## 数据库
###mysql，mongodb，rides的端口

面试数据库介绍的再好，不知到默认端口，也证明你没有经验。mysql：3306，mongdb：27017，rides：6379。
## 数据
### 数据来源的方式

1. webServer ：用户访问我们的网站，对日志进行收集，记录在反向的日志文件里 tomcat下logs
2. js代码嵌入前端页面（埋点）：js的sdk会获取用户行为，document会得到元素调用function，通过ngix集群进行日志收集。
3. db数据订阅工具，如开源的maxwell，canal等

