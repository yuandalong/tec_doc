# Elasticsearch学习笔记
### Elastic技术栈
简称ELK
* E Elasticsearch 分布式搜索引擎，可以做分析，可以水平收缩，动态扩容，restful api
* L Logstash 数据接入端
* K Kibana 前端可视化分析平台，报表展示
* Beats 更轻量级的数据接入端，相比Logstash，系统资源消耗更少
* X-Pack es官方的商业扩展包，收费的
    * Security 权限控制，可精确到字段
    * Alerting 通知，定制感兴趣的数据，出现后发送通知到指定的第三方通知系统，如邮件、短信
    * ML 非监督型面向持续性数据的机器学习，自动学习和训练，持续监测，自动发现异常数据
    * Monitoring 监控，如硬件方面、jvm方面
    * Reporting 数据导出，如导出pdf，cvs等
    * Graph 图分析，自动挖掘数据，建立数据之间的关系
* Elastic Cloud 官方的云环境，包括了X-Pack
* ECE 私有云 
* Elasticsearch-Hadoop 支持hadoop和spark

![技术栈](media/%E6%8A%80%E6%9C%AF%E6%A0%88.png)
![商业扩展](media/%E5%95%86%E4%B8%9A%E6%89%A9%E5%B1%95.png)

### ES
* 启动命令 bin/elasticsearch
* 配置文件 config
* 默认端口9200
* cat命令
浏览器访问127.0.0.1:9200/_cat 显示快速接口列表
    * _cat/health 集群状态
    * _cat/plugins 已安装插件
* 插件安装 bin/elasticsearch-plugin install file://本地路径，如安装x-pack 
* 输入输出 es的输入输出使用json格式，通过restful api访问，可直接用Kibana的devtools访问，GET查询，POST增加，PUT修改，DELETE删除
    * es restful api的url分三层，如twitter/doc/1，其中twitter是索引，doc是类型，1是id，分布对应es的_index,_type,_id，不指定id时会随机生成
    * GET twitter/doc/1 精确获取指定文档
    * GET twitter/_search 获取twitter下所有文档 
        可指定查寻条件
        * 单条件查询 {"query":{"match":{"字段名":"字段值"}}}
        * 多条件查询，即and {"bool":{"must":[{"match":{"字段名":"字段值"}},{"match":{"字段名2":"字段值2"}}]}}
        * 条件取反，即not {"bool":{"must-not":[{"match":{"字段名":"字段值"}}]}}
        * 可选，即or {"bool":{"should":[{"match":{"字段名":"字段值"}},{"match":{"字段名2":"字段值2"}}]}}
    * 条数查询 twitter/_search，参数同search
    * 设置索引分片数 
        PUT twitter
        {"settings":{"number_of_shards":1}}
        设置分片数为1
    
    * 批量插入数据 POST _bulk 
        * 数据格式为{index:{_index:"a",_type:"doc",_id:"不指定随机生成"}}{数据json串} 
        * 注意一条数据分两个json串，第一行是index，第二行是内容
    
    * 设置经纬度 twitter/doc/_mapping
        * 具体api查看文档 
    * 聚合统计
        * 范围统计：如年龄字段范围为10-80，使用聚合统计，统计出10-20，20-40，40-60，60-80的条数，可使用range选项
        * 按字段值分组：如统计每个年龄的人数，用terms
    
    * 分析器 twitter/_analyze
        * 通过{"analyzer":"分析器类型"}来设置查询时具体的分析器，如standard，simple等，可以用来做分词，具体参考api 
        * 通过{"tokenizer":"???","filter":["???"]}结合使用来设置过滤器，如大小写转换等，其中tokenizer用来做分词，filter用来做过滤，注意filter是数据，可以设置多个
         

### Kibana
* 启动命令 bin/kibana
* 配置
    * config/kibana.yml
    * es路径配置 elasticsearch.hosts: ["http://localhost:9200"]
    * es用户名、密码：elasticsearch.username: "user" 
    elasticsearch.password: "pass"
        * 启用x-pack后才需要配置，不启用的话es没有权限管理
* DevTools restful直接访问es
    * GET / 访问es根目录，与浏览器直接访问127.0.0.1:9200一样的效果
    * 